import pyshark
import re
import json
from datetime import datetime
from html import unescape
from bs4 import BeautifulSoup

def format_html_content(html_text):
    """æ ¼å¼åŒ–HTMLå†…å®¹ï¼Œä½¿å…¶æ›´æ˜“è¯»"""
    try:
        # è§£ç HTMLå®ä½“
        decoded_html = unescape(html_text)
        
        # ä½¿ç”¨BeautifulSoupè§£æå’Œæ ¼å¼åŒ–HTML
        soup = BeautifulSoup(decoded_html, 'html.parser')
        
        # æå–å…³é”®ä¿¡æ¯
        formatted_info = {
            'title': soup.title.string if soup.title else 'N/A',
            'meta_tags': [],
            'scripts': [],
            'stylesheets': [],
            'body_content_preview': '',
            'total_length': len(decoded_html),
            'formatted_html': soup.prettify()
        }
        
        # æå–metaæ ‡ç­¾
        for meta in soup.find_all('meta'):
            meta_info = {}
            for attr in ['name', 'content', 'property', 'charset']:
                if meta.get(attr):
                    meta_info[attr] = meta.get(attr)
            if meta_info:
                formatted_info['meta_tags'].append(meta_info)
        
        # æå–è„šæœ¬ä¿¡æ¯
        for script in soup.find_all('script'):
            script_info = {
                'src': script.get('src', 'inline'),
                'type': script.get('type', 'text/javascript'),
                'content_length': len(script.string) if script.string else 0
            }
            formatted_info['scripts'].append(script_info)
        
        # æå–æ ·å¼è¡¨ä¿¡æ¯
        for link in soup.find_all('link', rel='stylesheet'):
            formatted_info['stylesheets'].append({
                'href': link.get('href', ''),
                'type': link.get('type', 'text/css')
            })
        
        # æå–bodyå†…å®¹é¢„è§ˆ
        if soup.body:
            body_text = soup.body.get_text(strip=True)
            formatted_info['body_content_preview'] = body_text
        
        return formatted_info
        
    except Exception as e:
        return {
            'error': f'æ ¼å¼åŒ–å¤±è´¥: {str(e)}',
            'raw_preview': html_text,
            'total_length': len(html_text)
        }

def extract_raw_data(packet):
    """ä»æ•°æ®åŒ…ä¸­æå–åŸå§‹æ•°æ®"""
    raw_data = {
        'packet_number': packet.number,
        'timestamp': str(packet.sniff_time),  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        # ç§»é™¤packet_objï¼Œé¿å…åºåˆ—åŒ–é—®é¢˜
        'tcp_data': None,
        'http2_data': None,
        'encrypted_data': None,
        'decrypted_data': None
    }
    
    # æå–TCPå±‚åŸå§‹æ•°æ®
    if hasattr(packet, 'tcp'):
        tcp_info = {
            'stream': packet.tcp.stream if hasattr(packet.tcp, 'stream') else 'N/A',
            'seq': packet.tcp.seq if hasattr(packet.tcp, 'seq') else 'N/A',
            'payload': str(packet.tcp.payload) if hasattr(packet.tcp, 'payload') else 'N/A'
        }
        raw_data['tcp_data'] = tcp_info
    
    # æå–TLSå±‚æ•°æ®ï¼ˆç”¨äºå¯†æ–‡ï¼‰
    tls_data = None
    if hasattr(packet, 'tls'):
        try:
            if hasattr(packet.tls, 'app_data'):
                tls_data = str(packet.tls.app_data)
            elif hasattr(packet.tls, 'record'):
                tls_data = str(packet.tls.record)
        except:
            pass
    raw_data['tls_data'] = tls_data
    
    # æå–HTTP/2å±‚æ•°æ®
    if hasattr(packet, 'http2'):
        http2 = packet.http2
        http2_info = {
            'type': getattr(http2, 'type', 'N/A'),
            'streamid': getattr(http2, 'streamid', 'N/A'),
            'length': getattr(http2, 'length', 'N/A'),
            'flags': getattr(http2, 'flags', 'N/A'),
            'raw_layer': str(http2)  # ä¿ç•™PySharkçš„åŸå§‹è§£æ
        }
        
        # å°è¯•ç›´æ¥æå–HTTP/2æ•°æ®å­—æ®µçš„å®Œæ•´å†…å®¹
        try:
            # æ–¹æ³•1ï¼šå°è¯•è·å–http2.dataå­—æ®µ
            if hasattr(http2, 'data'):
                http2_info['data_field'] = str(http2.data)
            
            # æ–¹æ³•2ï¼šå°è¯•è·å–æ‰€æœ‰å¯ç”¨å­—æ®µ
            all_fields = []
            for field_name in http2._all_fields:
                if 'data' in field_name.lower():
                    field_value = http2.get_field_value(field_name)
                    if field_value:
                        all_fields.append({
                            'field_name': field_name,
                            'field_value': str(field_value)
                        })
            http2_info['data_fields'] = all_fields
            
        except Exception as e:
            http2_info['data_extraction_error'] = str(e)
        
        raw_data['http2_data'] = http2_info
        
        # ä»TCP payloadä¸­æå–HTTP/2å¸§çš„å®é™…æ•°æ®éƒ¨åˆ†
        if raw_data['tcp_data'] and raw_data['tcp_data']['payload'] != 'N/A':
            tcp_payload = raw_data['tcp_data']['payload']
            # HTTP/2å¸§æ ¼å¼ï¼š9å­—èŠ‚å¸§å¤´ + æ•°æ®
            # å°è¯•æå–å¸§æ•°æ®éƒ¨åˆ†ï¼ˆè·³è¿‡å¸§å¤´ï¼‰
            try:
                # å°†åå…­è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚
                payload_bytes = bytes.fromhex(tcp_payload.replace(':', ''))
                if len(payload_bytes) > 9:  # ç¡®ä¿æœ‰å¸§å¤´
                    frame_data = payload_bytes[9:]  # è·³è¿‡9å­—èŠ‚å¸§å¤´
                    http2_info['extracted_frame_data'] = frame_data.hex()
                    http2_info['extracted_frame_data_length'] = len(frame_data)
            except Exception as e:
                http2_info['frame_extraction_error'] = str(e)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºåŠ å¯†æ•°æ®è¿˜æ˜¯æ˜æ–‡æ•°æ®
        # æ£€æŸ¥æå–çš„å¸§æ•°æ®è€Œä¸æ˜¯PySharkçš„æ˜¾ç¤ºå†…å®¹
        if 'extracted_frame_data' in http2_info:
            frame_data_hex = http2_info['extracted_frame_data']
            try:
                # å°è¯•å°†åå…­è¿›åˆ¶è½¬æ¢ä¸ºæ–‡æœ¬
                frame_data_bytes = bytes.fromhex(frame_data_hex)
                frame_data_text = frame_data_bytes.decode('utf-8', errors='ignore')
                
                # æ›´å…¨é¢çš„æ˜æ–‡åˆ¤æ–­é€»è¾‘
                is_plaintext = False
                
                # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«å¯æ‰“å°çš„ASCIIå­—ç¬¦æ¯”ä¾‹
                printable_chars = sum(1 for c in frame_data_text if c.isprintable())
                printable_ratio = printable_chars / len(frame_data_text) if len(frame_data_text) > 0 else 0
                
                # 2. æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„æ–‡æœ¬æ¨¡å¼
                text_patterns = [
                    '<html', '<div', '<body', '<head', '<!doctype',  # HTMLæ ‡ç­¾
                    'http://', 'https://',  # URL
                    'content-type', 'user-agent', 'accept',  # HTTPå¤´
                    '{', '}', '[', ']',  # JSONæ ¼å¼
                    'var ', 'function', 'return',  # JavaScript
                    'charset=', 'encoding=',  # ç¼–ç ä¿¡æ¯
                ]
                
                has_text_patterns = any(pattern in frame_data_text.lower() for pattern in text_patterns)
                
                # 3. æ£€æŸ¥å­—èŠ‚ç†µï¼ˆç®€å•å®ç°ï¼‰
                byte_counts = {}
                for byte_val in frame_data_bytes:
                    byte_counts[byte_val] = byte_counts.get(byte_val, 0) + 1
                
                # è®¡ç®—ç®€å•çš„å­—èŠ‚åˆ†å¸ƒå‡åŒ€åº¦
                unique_bytes = len(byte_counts)
                total_bytes = len(frame_data_bytes)
                byte_diversity = unique_bytes / total_bytes if total_bytes > 0 else 0
                
                # åˆ¤æ–­é€»è¾‘ï¼š
                # - å¯æ‰“å°å­—ç¬¦æ¯”ä¾‹ > 70% ä¸”åŒ…å«æ–‡æœ¬æ¨¡å¼ï¼Œæˆ–
                # - å¯æ‰“å°å­—ç¬¦æ¯”ä¾‹ > 90%ï¼Œæˆ–
                # - å­—èŠ‚å¤šæ ·æ€§ < 0.8ï¼ˆè¡¨ç¤ºé‡å¤æ¨¡å¼è¾ƒå¤šï¼Œå¯èƒ½æ˜¯æ–‡æœ¬ï¼‰
                if (printable_ratio > 0.7 and has_text_patterns) or printable_ratio > 0.9 or byte_diversity < 0.8:
                    is_plaintext = True
                
                if is_plaintext:
                    # æ ¼å¼åŒ–å†…å®¹ï¼ˆå¦‚æœæ˜¯HTMLï¼‰
                    formatted_content = None
                    if any(tag in frame_data_text.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']):
                        formatted_content = format_html_content(frame_data_text)
                    
                    raw_data['decrypted_data'] = {
                        'type': 'PLAINTEXT_CONTENT',
                        'size': len(frame_data_hex),
                        'hex_data': frame_data_hex,
                        'text_preview': frame_data_text,
                        'formatted_content': formatted_content,
                        'contains_html': any(tag in frame_data_text.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']),
                        'printable_ratio': printable_ratio,
                        'has_text_patterns': has_text_patterns,
                        'byte_diversity': byte_diversity
                    }
                else:
                    raw_data['encrypted_data'] = {
                        'type': 'ENCRYPTED_BINARY',
                        'size': len(frame_data_hex),
                        'hex_data': frame_data_hex,
                        'contains_html': False,
                        'printable_ratio': printable_ratio,
                        'has_text_patterns': has_text_patterns,
                        'byte_diversity': byte_diversity
                    }
            except Exception as e:
                raw_data['encrypted_data'] = {
                    'type': 'ENCRYPTED_BINARY',
                    'size': len(frame_data_hex) if 'extracted_frame_data' in http2_info else 0,
                    'hex_data': frame_data_hex if 'extracted_frame_data' in http2_info else '',
                    'decode_error': str(e),
                    'contains_html': False
                }
        else:
            # å¦‚æœæ— æ³•æå–å¸§æ•°æ®ï¼Œå›é€€åˆ°PySharkçš„è§£æç»“æœ
            raw_layer_str = str(http2)
            
            # å¯¹PySharkè§£æç»“æœä¹Ÿåº”ç”¨ç›¸åŒçš„åˆ¤æ–­é€»è¾‘
            printable_chars = sum(1 for c in raw_layer_str if c.isprintable())
            printable_ratio = printable_chars / len(raw_layer_str) if len(raw_layer_str) > 0 else 0
            
            text_patterns = [
                '<html', '<div', '<body', '<head', '<!doctype',
                'http://', 'https://', 'content-type', 'user-agent', 'accept',
                '{', '}', '[', ']', 'var ', 'function', 'return',
                'charset=', 'encoding='
            ]
            has_text_patterns = any(pattern in raw_layer_str.lower() for pattern in text_patterns)
            
            if printable_ratio > 0.7 and has_text_patterns:
                # æ ¼å¼åŒ–HTMLå†…å®¹
                formatted_content = None
                if any(tag in raw_layer_str.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']):
                    formatted_content = format_html_content(raw_layer_str)
                
                raw_data['decrypted_data'] = {
                    'type': 'PLAINTEXT_CONTENT_FALLBACK',
                    'size': len(raw_layer_str),
                    'preview': raw_layer_str,
                    'formatted_content': formatted_content,
                    'contains_html': any(tag in raw_layer_str.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']),
                    'printable_ratio': printable_ratio,
                    'has_text_patterns': has_text_patterns,
                }
            else:
                raw_data['encrypted_data'] = {
                    'type': 'ENCRYPTED_OR_BINARY_FALLBACK',
                    'size': len(raw_layer_str),
                    'preview': raw_layer_str,
                    'contains_html': False,
                    'printable_ratio': printable_ratio,
                    'has_text_patterns': has_text_patterns
                }
    
    return raw_data


def save_comparison_data(packet_data_list, name):
    """ä¿å­˜å¯¹æ¯”æ•°æ®åˆ°æ–‡ä»¶"""
    # ä¿å­˜ä¸ºJSONæ ¼å¼
    with open(f'wiki/{name}_packet_comparison.json', 'w', encoding='utf-8') as f:
        json.dump(packet_data_list, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ä¸ºå¯è¯»çš„æ–‡æœ¬æ ¼å¼
    with open(f'wiki/{name}_packet_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(f"HTTP/2 æ•°æ®åŒ…å¯†æ–‡æ˜æ–‡å¯¹æ¯”åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
        f.write("=" * 80 + "\n\n")
        
        for i, packet_data in enumerate(packet_data_list, 1):
            f.write(f"æ•°æ®åŒ… #{packet_data['packet_number']} (ç¬¬{i}ä¸ª)\n")
            f.write(f"æ—¶é—´æˆ³: {packet_data['timestamp']}\n")
            f.write("-" * 60 + "\n")
            
            # HTTP/2åŸºæœ¬ä¿¡æ¯
            if packet_data['http2_data']:
                http2 = packet_data['http2_data']
                f.write(f"Type: {http2['type']}\n")
                f.write(f"Stream ID: {http2['streamid']}\n")
                f.write(f"Length: {http2['length']}\n")
                f.write(f"Flags: {http2['flags']}\n")
                f.write("\n")
            
            # å››è¡Œå…³é”®æ•°æ®
            # 1. å¯†æ–‡æ•°æ®ï¼ˆTLSå±‚çš„Application Dataï¼‰
            tls_data = packet_data.get('tls_data', 'N/A')
            if tls_data == 'N/A' or not tls_data:
                # å¦‚æœæ²¡æœ‰TLSæ•°æ®ï¼Œä½¿ç”¨TCPè½½è·ä½œä¸ºå¯†æ–‡
                if packet_data['tcp_data'] and packet_data['tcp_data']['payload'] != 'N/A':
                    tls_data = packet_data['tcp_data']['payload']
            f.write(f"å¯†æ–‡: {tls_data}\n")
            
            # 2. åŸå§‹æ˜æ–‡ï¼ˆwiresharkæŠ“åˆ°çš„åŸå§‹æ•°æ®åŒ…å†…å®¹ï¼‰
            if packet_data['tcp_data'] and packet_data['tcp_data']['payload'] != 'N/A':
                f.write(f"åŸå§‹æ˜æ–‡: {packet_data['tcp_data']['payload']}\n")
            else:
                f.write(f"åŸå§‹æ˜æ–‡: N/A\n")
            
            # 3. è§£ç åæ˜æ–‡ï¼ˆHTTP/2å±‚çš„Dataå¸§å†…å®¹ï¼‰
            # http2_data = "N/A"
            # if packet_data['decrypted_data']:
            #     if 'text_preview' in packet_data['decrypted_data']:
            #         http2_data = packet_data['decrypted_data']['text_preview']
            #     elif 'preview' in packet_data['decrypted_data']:
            #         http2_data = packet_data['decrypted_data']['preview']
            # elif packet_data['http2_data']:
            #     # ä½¿ç”¨HTTP/2å±‚çš„åŸå§‹è§£æç»“æœ
            #     http2_data = packet_data['http2_data']['raw_layer']
            # 
            # f.write(f"è§£ç åæ˜æ–‡: {http2_data}\n")
            
            # 4. äººè‚‰çœ¼å¯è¯»æ˜æ–‡ï¼ˆçœŸæ­£çš„å¯è§†åŒ–å†…å®¹ï¼‰
            readable_text = "N/A"
            if packet_data['http2_data']:
                http2_info = packet_data['http2_data']
                
                # ç›´æ¥ä½¿ç”¨raw_layerçš„å†…å®¹ä½œä¸ºå¯è§†åŒ–æ˜æ–‡
                # è¿™æ ·å¯ä»¥æ˜¾ç¤ºå®Œæ•´çš„HTTP/2è§£æä¿¡æ¯ï¼Œç±»ä¼¼äºtxtæ–‡ä»¶ä¸­çš„æ ¼å¼
                raw_layer = http2_info.get('raw_layer', '')
                
                if raw_layer:
                    # ä¿æŒåŸå§‹çš„raw_layeræ ¼å¼ï¼Œè¿™åŒ…å«äº†å®Œæ•´çš„HTTP/2å¸§è§£æä¿¡æ¯
                    # åŒ…æ‹¬å¸§ç±»å‹ã€æ ‡å¿—ä½ã€å¤´éƒ¨ä¿¡æ¯ã€cookieç­‰è¯¦ç»†å†…å®¹
                    readable_text = raw_layer
                else:
                    # å¦‚æœæ²¡æœ‰raw_layerï¼Œå›é€€åˆ°åŸæ¥çš„é€»è¾‘
                    readable_parts = []
                    
                    # æ·»åŠ å¸§ç±»å‹çš„å¯è¯»æè¿°
                    frame_type = http2_info.get('type', 'Unknown')
                    frame_type_desc = {
                        '0': 'DATAå¸§(æ•°æ®ä¼ è¾“)',
                        '1': 'HEADERSå¸§(HTTPå¤´)',
                        '2': 'PRIORITYå¸§(ä¼˜å…ˆçº§)',
                        '3': 'RST_STREAMå¸§(é‡ç½®æµ)',
                        '4': 'SETTINGSå¸§(è®¾ç½®)',
                        '5': 'PUSH_PROMISEå¸§(æ¨é€æ‰¿è¯º)',
                        '6': 'PINGå¸§(å¿ƒè·³)',
                        '7': 'GOAWAYå¸§(å…³é—­è¿æ¥)',
                        '8': 'WINDOW_UPDATEå¸§(çª—å£æ›´æ–°)',
                        '9': 'CONTINUATIONå¸§(å¤´éƒ¨å»¶ç»­)'
                    }.get(str(frame_type), f'æœªçŸ¥å¸§ç±»å‹({frame_type})')
                    
                    readable_parts.append(f"å¸§ç±»å‹: {frame_type_desc}")
                    
                    # æ ¹æ®å¸§ç±»å‹æå–ç›¸åº”çš„å¯è¯»ä¿¡æ¯
                    if str(frame_type) == '1':  # HEADERSå¸§
                        readable_parts.append("åŒ…å«HTTPè¯·æ±‚/å“åº”å¤´ä¿¡æ¯")
                    elif str(frame_type) == '0':  # DATAå¸§
                        if packet_data['decrypted_data']:
                            dec_data = packet_data['decrypted_data']
                            if dec_data.get('contains_html', False):
                                readable_parts.append("å†…å®¹: HTMLç½‘é¡µæ•°æ®")
                            elif 'text_preview' in dec_data:
                                text = dec_data['text_preview']
                                if text.strip().startswith('{') and text.strip().endswith('}'):
                                    readable_parts.append("å†…å®¹: JSONæ•°æ®")
                                elif 'function' in text or 'var ' in text:
                                    readable_parts.append("å†…å®¹: JavaScriptä»£ç ")
                                else:
                                    readable_parts.append("å†…å®¹: æ–‡æœ¬æ•°æ®")
                        else:
                            readable_parts.append("å†…å®¹: äºŒè¿›åˆ¶æ•°æ®")
                    elif str(frame_type) == '4':  # SETTINGSå¸§
                        readable_parts.append("å†…å®¹: HTTP/2è¿æ¥è®¾ç½®å‚æ•°")
                    elif str(frame_type) == '6':  # PINGå¸§
                        readable_parts.append("å†…å®¹: è¿æ¥ä¿æ´»å¿ƒè·³")
                    elif str(frame_type) == '8':  # WINDOW_UPDATEå¸§
                        readable_parts.append("å†…å®¹: æµé‡æ§åˆ¶çª—å£æ›´æ–°")
                    
                    # æ·»åŠ æ•°æ®å¤§å°ä¿¡æ¯
                    if 'length' in http2_info:
                        size = int(http2_info['length'])
                        if size > 1024:
                            size_desc = f"{size/1024:.1f}KB"
                        else:
                            size_desc = f"{size}å­—èŠ‚"
                        readable_parts.append(f"å¤§å°: {size_desc}")
                    
                    # æ·»åŠ æµIDä¿¡æ¯
                    if 'streamid' in http2_info:
                        readable_parts.append(f"æµID: {http2_info['streamid']}")
                    
                    if readable_parts:
                        readable_text = ' | '.join(readable_parts)
                    else:
                        readable_text = "[æ— æ³•è§£æçš„HTTP/2å¸§æ•°æ®]"
            else:
                readable_text = "[éHTTP/2æ•°æ®åŒ…]"
            
            f.write(f"å¯è§†åŒ–æ˜æ–‡: {readable_text}\n")
            
            f.write("=" * 80 + "\n\n")

def main():
    print("å¼€å§‹åˆ†æHTTP/2æ•°æ®åŒ…çš„å¯†æ–‡å’Œæ˜æ–‡æ•°æ®ï¼ˆæ”¹è¿›ç‰ˆï¼‰...")
    
    name_package_dict = {
        "å¥¥ç‰¹æ›¼": "tcp.stream eq 8 and http2.streamid eq 1",
        "å‡é¢éª‘å£«": "tcp.stream eq 33 and http2.streamid eq 19",
        "å°¼äºšåŠ æ‹‰ç€‘å¸ƒ": "tcp.stream eq 70 and http2.streamid eq 15",
        "å­™ç­–": "tcp.stream eq 12 and http2.streamid eq 21",
        "äº”å¤§æ¹–": "tcp.stream eq 37 and http2.streamid eq 23",
    }

    for name, filter in name_package_dict.items():
        cap = pyshark.FileCapture(f'wiki/{name}.pcapng', 
            display_filter=filter, 
            tshark_path='D:\\else\\wireshark\\tshark.exe'
            )
        packet_data_list = []
        encrypted_count = 0
        decrypted_count = 0
        
        for pkt in cap:
            print(f"å¤„ç†æ•°æ®åŒ… #{pkt.number}...")
            
            # æå–æ•°æ®åŒ…ä¿¡æ¯
            packet_data = extract_raw_data(pkt)
            packet_data_list.append(packet_data)
            
            # ç»Ÿè®¡åŠ å¯†å’Œæ˜æ–‡æ•°æ®åŒ…
            if packet_data['encrypted_data']:
                encrypted_count += 1
                enc = packet_data['encrypted_data']
                print(f"  ğŸ”’ å‘ç°åŠ å¯†æ•°æ® (å¤§å°: {enc['size']} å­—ç¬¦)")
                if 'printable_ratio' in enc:
                    print(f"      å¯æ‰“å°å­—ç¬¦æ¯”ä¾‹: {enc['printable_ratio']:.2%}")
            
            if packet_data['decrypted_data']:
                decrypted_count += 1
                dec = packet_data['decrypted_data']
                print(f"  ğŸ”“ å‘ç°æ˜æ–‡æ•°æ® (å¤§å°: {dec['size']} å­—ç¬¦)")
                if 'printable_ratio' in dec:
                    print(f"      å¯æ‰“å°å­—ç¬¦æ¯”ä¾‹: {dec['printable_ratio']:.2%}")
        
        # ä¿å­˜å¯¹æ¯”æ•°æ®
        save_comparison_data(packet_data_list, name)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š åˆ†æå®Œæˆ!")
        print(f"æ€»æ•°æ®åŒ…æ•°: {len(packet_data_list)}")
        print(f"åŠ å¯†æ•°æ®åŒ…: {encrypted_count}")
        print(f"æ˜æ–‡æ•°æ®åŒ…: {decrypted_count}")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - {name}_packet_comparison.json (JSONæ ¼å¼)")
        print(f"  - {name}_packet_comparison.txt (å¯è¯»æ ¼å¼)")

if __name__ == "__main__":
    main()