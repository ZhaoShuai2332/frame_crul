import pyshark
import re
import json
from datetime import datetime
from html import unescape
from bs4 import BeautifulSoup

def format_html_content(html_text):
    """æ ¼å¼åŒ–HTMLå†…å®¹ï¼Œä½¿å…¶æ›´æ˜“è¯»"""
    try:
        # è§£ç HTMLå®ä½“
        decoded_html = unescape(html_text)
        
        # ä½¿ç”¨BeautifulSoupè§£æå’Œæ ¼å¼åŒ–HTML
        soup = BeautifulSoup(decoded_html, 'html.parser')
        
        # æå–å…³é”®ä¿¡æ¯
        formatted_info = {
            'title': soup.title.string if soup.title else 'N/A',
            'meta_tags': [],
            'scripts': [],
            'stylesheets': [],
            'body_content_preview': '',
            'total_length': len(decoded_html),
            'formatted_html': soup.prettify()[:2000]  # é™åˆ¶é•¿åº¦
        }
        
        # æå–metaæ ‡ç­¾
        for meta in soup.find_all('meta'):
            meta_info = {}
            for attr in ['name', 'content', 'property', 'charset']:
                if meta.get(attr):
                    meta_info[attr] = meta.get(attr)
            if meta_info:
                formatted_info['meta_tags'].append(meta_info)
        
        # æå–è„šæœ¬ä¿¡æ¯
        for script in soup.find_all('script'):
            script_info = {
                'src': script.get('src', 'inline'),
                'type': script.get('type', 'text/javascript'),
                'content_length': len(script.string) if script.string else 0
            }
            formatted_info['scripts'].append(script_info)
        
        # æå–æ ·å¼è¡¨ä¿¡æ¯
        for link in soup.find_all('link', rel='stylesheet'):
            formatted_info['stylesheets'].append({
                'href': link.get('href', ''),
                'type': link.get('type', 'text/css')
            })
        
        # æå–bodyå†…å®¹é¢„è§ˆ
        if soup.body:
            body_text = soup.body.get_text(strip=True)
            formatted_info['body_content_preview'] = body_text[:500]
        
        return formatted_info
        
    except Exception as e:
        return {
            'error': f'æ ¼å¼åŒ–å¤±è´¥: {str(e)}',
            'raw_preview': html_text[:500],
            'total_length': len(html_text)
        }

def extract_raw_data(packet):
    """æå–æ•°æ®åŒ…çš„åŸå§‹æ•°æ®"""
    raw_data = {
        'packet_number': packet.number,
        'timestamp': str(packet.sniff_time) if hasattr(packet, 'sniff_time') else 'N/A',
        'tcp_data': None,
        'http2_data': None,
        'encrypted_data': None,
        'decrypted_data': None
    }
    
    # æå–TCPå±‚åŸå§‹æ•°æ®
    if hasattr(packet, 'tcp'):
        tcp_info = {
            'stream': packet.tcp.stream if hasattr(packet.tcp, 'stream') else 'N/A',
            'seq': packet.tcp.seq if hasattr(packet.tcp, 'seq') else 'N/A',
            'payload': str(packet.tcp.payload) if hasattr(packet.tcp, 'payload') else 'N/A'
        }
        raw_data['tcp_data'] = tcp_info
    
    # æå–HTTP/2å±‚æ•°æ®
    if hasattr(packet, 'http2'):
        http2 = packet.http2
        http2_info = {
            'type': getattr(http2, 'type', 'N/A'),
            'streamid': getattr(http2, 'streamid', 'N/A'),
            'length': getattr(http2, 'length', 'N/A'),
            'flags': getattr(http2, 'flags', 'N/A'),
            'raw_layer': str(http2)  # ä¿ç•™PySharkçš„åŸå§‹è§£æ
        }
        
        # å°è¯•ç›´æ¥æå–HTTP/2æ•°æ®å­—æ®µçš„å®Œæ•´å†…å®¹
        try:
            # æ–¹æ³•1ï¼šå°è¯•è·å–http2.dataå­—æ®µ
            if hasattr(http2, 'data'):
                http2_info['data_field'] = str(http2.data)
            
            # æ–¹æ³•2ï¼šå°è¯•è·å–æ‰€æœ‰å¯ç”¨å­—æ®µ
            all_fields = []
            for field_name in http2._all_fields:
                if 'data' in field_name.lower():
                    field_value = http2.get_field_value(field_name)
                    if field_value:
                        all_fields.append({
                            'field_name': field_name,
                            'field_value': str(field_value)
                        })
            http2_info['data_fields'] = all_fields
            
        except Exception as e:
            http2_info['data_extraction_error'] = str(e)
        
        raw_data['http2_data'] = http2_info
        
        # ä»TCP payloadä¸­æå–HTTP/2å¸§çš„å®é™…æ•°æ®éƒ¨åˆ†
        if raw_data['tcp_data'] and raw_data['tcp_data']['payload'] != 'N/A':
            tcp_payload = raw_data['tcp_data']['payload']
            # HTTP/2å¸§æ ¼å¼ï¼š9å­—èŠ‚å¸§å¤´ + æ•°æ®
            # å°è¯•æå–å¸§æ•°æ®éƒ¨åˆ†ï¼ˆè·³è¿‡å¸§å¤´ï¼‰
            try:
                # å°†åå…­è¿›åˆ¶å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚
                payload_bytes = bytes.fromhex(tcp_payload.replace(':', ''))
                if len(payload_bytes) > 9:  # ç¡®ä¿æœ‰å¸§å¤´
                    frame_data = payload_bytes[9:]  # è·³è¿‡9å­—èŠ‚å¸§å¤´
                    http2_info['extracted_frame_data'] = frame_data.hex()
                    http2_info['extracted_frame_data_length'] = len(frame_data)
            except Exception as e:
                http2_info['frame_extraction_error'] = str(e)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºåŠ å¯†æ•°æ®è¿˜æ˜¯æ˜æ–‡æ•°æ®
        # æ£€æŸ¥æå–çš„å¸§æ•°æ®è€Œä¸æ˜¯PySharkçš„æ˜¾ç¤ºå†…å®¹
        if 'extracted_frame_data' in http2_info:
            frame_data_hex = http2_info['extracted_frame_data']
            try:
                # å°è¯•å°†åå…­è¿›åˆ¶è½¬æ¢ä¸ºæ–‡æœ¬
                frame_data_bytes = bytes.fromhex(frame_data_hex)
                frame_data_text = frame_data_bytes.decode('utf-8', errors='ignore')
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«HTMLæ ‡ç­¾
                if any(tag in frame_data_text.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']):
                    # æ ¼å¼åŒ–HTMLå†…å®¹
                    formatted_content = format_html_content(frame_data_text)
                    
                    raw_data['decrypted_data'] = {
                        'type': 'HTML_CONTENT',
                        'size': len(frame_data_hex),
                        'hex_data': frame_data_hex,
                        'text_preview': frame_data_text[:500],
                        'formatted_content': formatted_content,  # æ–°å¢æ ¼å¼åŒ–å­—æ®µ
                        'contains_html': True
                    }
                else:
                    raw_data['encrypted_data'] = {
                        'type': 'ENCRYPTED_BINARY',
                        'size': len(frame_data_hex),
                        'hex_data': frame_data_hex,
                        'contains_html': False
                    }
            except Exception as e:
                raw_data['encrypted_data'] = {
                    'type': 'ENCRYPTED_BINARY',
                    'size': len(frame_data_hex) if 'extracted_frame_data' in http2_info else 0,
                    'hex_data': frame_data_hex if 'extracted_frame_data' in http2_info else '',
                    'decode_error': str(e),
                    'contains_html': False
                }
        else:
            # å¦‚æœæ— æ³•æå–å¸§æ•°æ®ï¼Œå›é€€åˆ°PySharkçš„è§£æç»“æœ
            raw_layer_str = str(http2)
            if any(tag in raw_layer_str.lower() for tag in ['<html', '<div', '<body', '<head', '<!doctype']):
                # æ ¼å¼åŒ–HTMLå†…å®¹
                formatted_content = format_html_content(raw_layer_str)
                
                raw_data['decrypted_data'] = {
                    'type': 'HTML_CONTENT_FALLBACK',
                    'size': len(raw_layer_str),
                    'preview': raw_layer_str,
                    'formatted_content': formatted_content,  # æ–°å¢æ ¼å¼åŒ–å­—æ®µ
                    'contains_html': True
                }
            else:
                raw_data['encrypted_data'] = {
                    'type': 'ENCRYPTED_OR_BINARY_FALLBACK',
                    'size': len(raw_layer_str),
                    'preview': raw_layer_str,
                    'contains_html': False
                }
    
    return raw_data


def save_comparison_data(packet_data_list, name):
    """ä¿å­˜å¯¹æ¯”æ•°æ®åˆ°æ–‡ä»¶"""
    # ä¿å­˜ä¸ºJSONæ ¼å¼
    with open(f'wiki/{name}_packet_comparison.json', 'w', encoding='utf-8') as f:
        json.dump(packet_data_list, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜ä¸ºå¯è¯»çš„æ–‡æœ¬æ ¼å¼
    with open(f'wiki/{name}_packet_comparison.txt', 'w', encoding='utf-8') as f:
        f.write(f"HTTP/2 æ•°æ®åŒ…å¯†æ–‡æ˜æ–‡å¯¹æ¯”åˆ†æ\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n")
        f.write("=" * 80 + "\n\n")
        
        for i, packet_data in enumerate(packet_data_list, 1):
            f.write(f"æ•°æ®åŒ… #{packet_data['packet_number']} (ç¬¬{i}ä¸ª)\n")
            f.write(f"æ—¶é—´æˆ³: {packet_data['timestamp']}\n")
            f.write("-" * 60 + "\n")
            
            # TCPä¿¡æ¯
            if packet_data['tcp_data']:
                tcp = packet_data['tcp_data']
                f.write(f"TCPä¿¡æ¯:\n")
                f.write(f"  Stream: {tcp['stream']}\n")
                f.write(f"  Sequence: {tcp['seq']}\n")
                # TLSå¯†æ–‡
                f.write(f"  Payload: {tcp['payload']}\n\n")
            
            # HTTP/2ä¿¡æ¯
            if packet_data['http2_data']:
                http2 = packet_data['http2_data']
                f.write(f"HTTP/2ä¿¡æ¯:\n")
                f.write(f"  Type: {http2['type']}\n")
                f.write(f"  Stream ID: {http2['streamid']}\n")
                f.write(f"  Length: {http2['length']}\n")
                f.write(f"  Flags: {http2['flags']}\n")
                # Httpæ˜æ–‡
                f.write(f"  Raw Layer: {http2['raw_layer']}\n\n")
                
                # æ·»åŠ æå–çš„å¸§æ•°æ®ä¿¡æ¯
                if 'extracted_frame_data' in http2:
                    f.write(f"  æå–çš„å¸§æ•°æ®é•¿åº¦: {http2['extracted_frame_data_length']} å­—èŠ‚\n")
                    f.write(f"  æå–çš„å¸§æ•°æ®(åå…­è¿›åˆ¶): {http2['extracted_frame_data'][:100]}...\n\n")
            
            # åŠ å¯†æ•°æ®
            if packet_data['encrypted_data']:
                enc = packet_data['encrypted_data']
                f.write(f"ğŸ”’ åŠ å¯†æ•°æ®:\n")
                f.write(f"  ç±»å‹: {enc['type']}\n")
                f.write(f"  å¤§å°: {enc['size']} å­—ç¬¦\n")
                
                # æ ¹æ®ä¸åŒçš„å­—æ®µç»“æ„é€‰æ‹©æ˜¾ç¤ºå†…å®¹
                if 'hex_data' in enc:
                    f.write(f"  åå…­è¿›åˆ¶æ•°æ®: {enc['hex_data']}\n")
                elif 'preview' in enc:
                    f.write(f"  é¢„è§ˆå†…å®¹: {enc['preview']}\n")
                
                if 'decode_error' in enc:
                    f.write(f"  è§£ç é”™è¯¯: {enc['decode_error']}\n")
                f.write("\n")
            
            # æ˜æ–‡æ•°æ®
            if packet_data['decrypted_data']:
                dec = packet_data['decrypted_data']
                f.write(f"ğŸ”“ æ˜æ–‡æ•°æ®:\n")
                f.write(f"  ç±»å‹: {dec['type']}\n")
                f.write(f"  å¤§å°: {dec['size']} å­—ç¬¦\n")
                f.write(f"  åŒ…å«HTML: {dec['contains_html']}\n")
                
                # æ ¹æ®ä¸åŒçš„å­—æ®µç»“æ„é€‰æ‹©æ˜¾ç¤ºå†…å®¹
                if 'text_preview' in dec:
                    f.write(f"  æ–‡æœ¬é¢„è§ˆ: {dec['text_preview']}\n")
                    if 'hex_data' in dec:
                        f.write(f"  åå…­è¿›åˆ¶æ•°æ®: {dec['hex_data']}\n")
                elif 'preview' in dec:
                    f.write(f"  é¢„è§ˆå†…å®¹: {dec['preview']}\n")
                f.write("\n")
            
            f.write("=" * 80 + "\n\n")

def main():
    print("å¼€å§‹åˆ†æHTTP/2æ•°æ®åŒ…çš„å¯†æ–‡å’Œæ˜æ–‡æ•°æ®...")
    
    name_package_dict = {
        "å¥¥ç‰¹æ›¼": "tcp.stream eq 8 and http2.streamid eq 1",
        "å‡é¢éª‘å£«": "tcp.stream eq 33 and http2.streamid eq 19",
        "å°¼äºšåŠ æ‹‰ç€‘å¸ƒ": "tcp.stream eq 70 and http2.streamid eq 15",
        "å­™ç­–": "tcp.stream eq 12 and http2.streamid eq 21",
        "äº”å¤§æ¹–": "tcp.stream eq 37 and http2.streamid eq 23",
    }

    for name, filter in name_package_dict.items():
        cap = pyshark.FileCapture(f'wiki/{name}.pcapng', 
            display_filter=filter, 
            tshark_path='D:\\else\\wireshark\\tshark.exe'
            )
        packet_data_list = []
        encrypted_count = 0
        decrypted_count = 0
        
        for pkt in cap:
            print(f"å¤„ç†æ•°æ®åŒ… #{pkt.number}...")
            
            # æå–æ•°æ®åŒ…ä¿¡æ¯
            packet_data = extract_raw_data(pkt)
            packet_data_list.append(packet_data)
            
            # ç»Ÿè®¡åŠ å¯†å’Œæ˜æ–‡æ•°æ®åŒ…
            if packet_data['encrypted_data']:
                encrypted_count += 1
                print(f"  ğŸ”’ å‘ç°åŠ å¯†æ•°æ® (å¤§å°: {packet_data['encrypted_data']['size']} å­—ç¬¦)")
            
            if packet_data['decrypted_data']:
                decrypted_count += 1
                print(f"  ğŸ”“ å‘ç°æ˜æ–‡æ•°æ® (å¤§å°: {packet_data['decrypted_data']['size']} å­—ç¬¦)")
        
        # ä¿å­˜å¯¹æ¯”æ•°æ®
        save_comparison_data(packet_data_list, name)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š åˆ†æå®Œæˆ!")
        print(f"æ€»æ•°æ®åŒ…æ•°: {len(packet_data_list)}")
        print(f"åŠ å¯†æ•°æ®åŒ…: {encrypted_count}")
        print(f"æ˜æ–‡æ•°æ®åŒ…: {decrypted_count}")
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - {name}_packet_comparison.json (JSONæ ¼å¼)")
        print(f"  - {name}_packet_comparison.txt (å¯è¯»æ ¼å¼)")

if __name__ == "__main__":
    main()